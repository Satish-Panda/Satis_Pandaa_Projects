# -*- coding: utf-8 -*-
"""Evaluate.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Znhmh5XqD-ECD5hnsjDgUFDynkA5OcrX
"""

import numpy as np
import pandas as pd


def evaluate():
    # Input the csv file
    """
    Sample evaluation function
    Don't modify this function
    """
    df = pd.read_csv('sample_input.csv')

    actual_close = np.loadtxt('sample_close.txt')

    pred_close = predict_func(df)

    # Calculation of squared_error
    actual_close = np.array(actual_close)
    pred_close = np.array(pred_close)
    mean_square_error = np.mean(np.square(actual_close-pred_close))


    pred_prev = [df['Close'].iloc[-1]]
    pred_prev.append(pred_close[0])
    pred_curr = pred_close

    actual_prev = [df['Close'].iloc[-1]]
    actual_prev.append(actual_close[0])
    actual_curr = actual_close

    # Calculation of directional_accuracy
    pred_dir = np.array(pred_curr)-np.array(pred_prev)
    actual_dir = np.array(actual_curr)-np.array(actual_prev)
    dir_accuracy = np.mean((pred_dir*actual_dir)>0)*100

    print(f'Mean Square Error: {mean_square_error:.6f}\nDirectional Accuracy: {dir_accuracy:.1f}')


def predict_func(data):
        import pandas as pd
        import numpy as np
        from scipy.interpolate import CubicSpline
        interpolate_columns = data.columns[data.columns != 'Date']

        for column in interpolate_columns:
            column_values = data[column].values
            not_null_indices = ~pd.isnull(column_values)
            indices = pd.Series(range(len(column_values)))
            cs = CubicSpline(indices[not_null_indices], column_values[not_null_indices])
            data[column] = cs(indices)



        from numpy import array
        from numpy import hstack


        def split_sequences( sequences, n_steps_in, n_steps_out):
                  X, y = list(), list()
                  for i in range(len(sequences)):
                      # find the end of this pattern
                      end_ix = i + n_steps_in
                      out_end_ix = end_ix + n_steps_out
                      # check if we are beyond the dataset
                      if out_end_ix > len(sequences):
                          break
                      # gather input and output parts of the pattern
                      seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix:out_end_ix, :]
                      X.append(seq_x)
                      y.append(seq_y)

                  return array(X), array(y)


        # define input sequence
        array_Open	= np.array(data['Open'])
        array_High	= np.array(data['High'])
        array_Low	  = np.array(data['Low'])
        array_Close	= np.array(data['Close'])
        array_Adj   = np.array(data['Adj Close'])
        array_Volume =  np.array(data['Volume'])

        # convert to [rows, columns] structure
        array_Open = array_Open.reshape((len(array_Open), 1))
        array_High = array_High.reshape((len(array_High), 1))
        array_Low = array_Low.reshape((len(array_Low), 1))
        array_Close = array_Close.reshape((len(array_Close), 1))
        array_Adj = array_Adj.reshape((len(array_Adj), 1))
        array_Volume = array_Volume.reshape((len(array_Volume), 1))

        # horizontally stack columns
        dataset = hstack((array_Open,
                          array_High,
                          array_Low,
                          array_Close,
                          #array_Adj,
                          #array_Volume
                          ))
        n_steps_in, n_steps_out = 5, 2
        # covert into input/output
        X, y = split_sequences(dataset, n_steps_in, n_steps_out)

        # multivariate multi-step encoder-decoder lstm example
        from numpy import array
        from numpy import hstack
        from keras.models import Sequential
        from keras.layers import LSTM
        from keras.layers import Dense
        from keras.layers import RepeatVector
        from keras.layers import TimeDistributed
        from keras.layers import Bidirectional

        import json
        from keras.models import model_from_json
        # multivariate multi-step data preparation
        # Load the saved model architecture
        with open('model_architecture.json', 'r') as json_file:
            model_architecture = json_file.read()
        loaded_model = model_from_json(model_architecture)

        # Load the saved model weights
        loaded_model.load_weights('model_weights.h5')

        # Load the model parameters
        with open('model_parameters.json', 'r') as json_file:
            parameters = json.load(json_file)
        n_steps_in = parameters['n_steps_in']
        n_steps_out = parameters['n_steps_out']
        n_features = parameters['n_features']

        # Perform evaluation using the loaded model

        x_input = dataset[len(dataset)-n_steps_in-2:len(dataset)-2,:]
        x_input = x_input.reshape((1, n_steps_in, n_features))

        yhat = loaded_model.predict(x_input, verbose=0)

        return [yhat[0][0][3],yhat[0][1][3]]

if __name__== "__main__":
    evaluate()
